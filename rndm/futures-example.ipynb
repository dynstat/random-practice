{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Futures in Python: From Basic to Advanced\n",
    "\n",
    "## 1. Introduction to Futures\n",
    "\n",
    "Futures in Python represent the result of asynchronous computations. They are a powerful tool for managing concurrent operations and can significantly improve the performance of I/O-bound and CPU-bound tasks.\n",
    "\n",
    "Analogy: Think of a future as a 'promise' or an 'IOU' (I Owe You) note. When you start a task, you get a future object immediately, which is like receiving an IOU. You can continue with other work, and when you need the result, you can 'cash in' the IOU to get the actual value.\n",
    "\n",
    "Let's start with a simple example to illustrate the concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def slow_operation(seconds):\n",
    "    time.sleep(seconds)  # Simulate a time-consuming operation\n",
    "    return f\"Operation completed in {seconds} seconds\"\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit the task and get a future\n",
    "    future = executor.submit(slow_operation, 3)\n",
    "    \n",
    "    print(\"Future created. Doing other work...\")\n",
    "    time.sleep(1)  # Simulate other work\n",
    "    \n",
    "    # Get the result from the future\n",
    "    result = future.result()\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "1. We define a `slow_operation` function that simulates a time-consuming task.\n",
    "2. We create a `ThreadPoolExecutor` to manage concurrent operations.\n",
    "3. We submit our task to the executor, which immediately returns a future object.\n",
    "4. We can do other work while the future is being processed.\n",
    "5. When we need the result, we call `future.result()`, which will wait if necessary and then return the result.\n",
    "\n",
    "This demonstrates the basic concept of futures: they allow us to start a task and continue with other work, checking for the result when we need it.\n",
    "\n",
    "## 2. Basics of Asyncio\n",
    "\n",
    "Before diving deeper into futures, it's important to understand the basics of asyncio, as it's closely related to how futures work in Python.\n",
    "\n",
    "Asyncio is a library for writing concurrent code using the async/await syntax. It's particularly useful for I/O-bound and high-level structured network code.\n",
    "\n",
    "Analogy: Think of asyncio as a juggler. A juggler can keep multiple balls in the air by quickly switching attention between them. Similarly, asyncio can manage multiple tasks by switching between them when they're waiting for I/O operations.\n",
    "\n",
    "Let's see a basic asyncio example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "async def main():\n",
    "    print(\"started at\", time.strftime(\"%X\"))\n",
    "\n",
    "    await say_after(1, 'hello')\n",
    "    await say_after(2, 'world')\n",
    "\n",
    "    print(\"finished at\", time.strftime(\"%X\"))\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "1. We define an asynchronous function `say_after` that waits for a specified delay and then prints a message.\n",
    "2. Our `main` function calls `say_after` twice, waiting for each to complete before moving on.\n",
    "3. We use `asyncio.run()` to run our main coroutine.\n",
    "\n",
    "This is a synchronous use of asyncio. In the next section, we'll see how to use futures with asyncio for concurrent operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concurrent Futures\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables. It abstracts the complexities of using threads or processes, making it easier to write concurrent code.\n",
    "\n",
    "Analogy: Think of `concurrent.futures` as a team of workers. You can assign tasks to this team, and they'll work on them concurrently. You can check on the progress of any task at any time, or wait for all tasks to complete.\n",
    "\n",
    "Let's explore the two main types of executors in `concurrent.futures`: ThreadPoolExecutor and ProcessPoolExecutor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ThreadPoolExecutor\n",
    "\n",
    "ThreadPoolExecutor is used for I/O-bound tasks. It's suitable when your tasks spend a lot of time waiting for external operations (like network requests or file I/O).\n",
    "\n",
    "Let's see an example where we use ThreadPoolExecutor to download multiple web pages concurrently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def download_page(url):\n",
    "    response = requests.get(url)\n",
    "    return f\"Downloaded {url}, status: {response.status_code}, length: {len(response.text)}\"\n",
    "\n",
    "urls = [\n",
    "    'https://www.example.com',\n",
    "    'https://www.python.org',\n",
    "    'https://www.github.com',\n",
    "    'https://www.stackoverflow.com'\n",
    "]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit all tasks and create a map of futures to their URLs\n",
    "    future_to_url = {executor.submit(download_page, url): url for url in urls}\n",
    "    \n",
    "    # Iterate over the futures as they complete\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print(f\"{url} generated an exception: {exc}\")\n",
    "        else:\n",
    "            print(data)\n",
    "\n",
    "print(f\"Total time taken: {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this example:\n",
    "\n",
    "1. We define a `download_page` function that downloads a webpage and returns a string with information about the download.\n",
    "\n",
    "2. We create a list of URLs to download.\n",
    "\n",
    "3. We use a `ThreadPoolExecutor` with a maximum of 4 workers. This means up to 4 downloads can happen concurrently.\n",
    "\n",
    "4. We submit all tasks to the executor using a dictionary comprehension. This creates a mapping of Future objects to their corresponding URLs.\n",
    "\n",
    "5. We use `concurrent.futures.as_completed()` to iterate over the futures as they complete. This allows us to process results as soon as they're available, rather than waiting for all tasks to finish.\n",
    "\n",
    "6. For each completed future, we retrieve its result (or catch any exceptions), and print the output.\n",
    "\n",
    "7. Finally, we print the total time taken for all downloads.\n",
    "\n",
    "This example demonstrates how ThreadPoolExecutor can significantly speed up I/O-bound operations by performing them concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ProcessPoolExecutor\n",
    "\n",
    "While ThreadPoolExecutor is great for I/O-bound tasks, ProcessPoolExecutor is better suited for CPU-bound tasks. It uses separate processes instead of threads, which allows it to bypass the Global Interpreter Lock (GIL) and achieve true parallelism on multi-core systems.\n",
    "\n",
    "Let's see an example where we use ProcessPoolExecutor to perform a CPU-intensive task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "import time\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(math.sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def count_primes(start, end):\n",
    "    return sum(1 for n in range(start, end) if is_prime(n))\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Define the range to search for primes\n",
    "    start, end = 1, 10**7\n",
    "    \n",
    "    # Split the range into chunks for each process\n",
    "    chunk_size = (end - start) // 4\n",
    "    ranges = [(i, i + chunk_size) for i in range(start, end, chunk_size)]\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(lambda r: count_primes(*r), ranges)\n",
    "    \n",
    "    total_primes = sum(results)\n",
    "    \n",
    "    print(f\"Found {total_primes} prime numbers in range {start} to {end}\")\n",
    "    print(f\"Time taken: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this example:\n",
    "\n",
    "1. We define an `is_prime` function to check if a number is prime.\n",
    "\n",
    "2. We define a `count_primes` function that counts the number of primes in a given range.\n",
    "\n",
    "3. In the `main` function:\n",
    "   - We set the range to search for primes (1 to 10^7).\n",
    "   - We split this range into 4 chunks, one for each process.\n",
    "\n",
    "4. We use a `ProcessPoolExecutor` to distribute the work across multiple processes.\n",
    "\n",
    "5. We use `executor.map()` to apply our `count_primes` function to each range. This returns an iterator of results.\n",
    "\n",
    "6. We sum up the results to get the total number of primes found.\n",
    "\n",
    "7. Finally, we print the results and the time taken.\n",
    "\n",
    "This example shows how ProcessPoolExecutor can be used to parallelize CPU-intensive tasks across multiple cores, potentially providing significant speedup on multi-core systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding Futures: Internal Flow and Analogies\n",
    "\n",
    "To understand how futures work internally, let's use an analogy of a coffee shop. In this analogy:\n",
    "- The main program is the cashier\n",
    "- The ThreadPoolExecutor is the team of baristas\n",
    "- Each future is an order ticket\n",
    "- The tasks are different coffee orders\n",
    "\n",
    "Here's a diagram to visualize this:\n",
    "\n",
    "```\n",
    "                 +-------------+\n",
    "                 |   Cashier   |\n",
    "                 | (Main Thread) |\n",
    "                 +-------------+\n",
    "                        |\n",
    "                        | Submit orders\n",
    "                        v\n",
    "            +------------------------+\n",
    "            |    ThreadPoolExecutor  |\n",
    "            | (Team of Baristas)     |\n",
    "            +------------------------+\n",
    "                 |       |       |\n",
    "            +----+   +---+   +---+\n",
    "            |        |       |\n",
    "         Future1  Future2  Future3\n",
    "         (Order1) (Order2) (Order3)\n",
    "```\n",
    "\n",
    "Let's implement this analogy in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "import random\n",
    "\n",
    "def make_coffee(order):\n",
    "    # Simulate coffee making process\n",
    "    print(f\"Starting to make {order}\")\n",
    "    time.sleep(random.uniform(1, 3))  # Random time to make coffee\n",
    "    return f\"{order} is ready!\"\n",
    "\n",
    "def coffee_shop():\n",
    "    orders = ['Espresso', 'Latte', 'Cappuccino', 'Americano']\n",
    "    \n",
    "    print(\"Coffee shop is open!\")\n",
    "    \n",
    "    # Create a ThreadPoolExecutor with 2 workers (baristas)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as barista_team:\n",
    "        # Submit all orders and create a map of futures to their orders\n",
    "        future_to_order = {barista_team.submit(make_coffee, order): order for order in orders}\n",
    "        \n",
    "        print(\"All orders submitted to baristas. Cashier is free now.\")\n",
    "        \n",
    "        # Simulate cashier doing other work\n",
    "        time.sleep(1)\n",
    "        print(\"Cashier is checking the status of orders...\")\n",
    "        \n",
    "        # Check and collect finished orders\n",
    "        for future in concurrent.futures.as_completed(future_to_order):\n",
    "            order = future_to_order[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"{order} order failed: {e}\")\n",
    "            else:\n",
    "                print(f\"Cashier: {result}\")\n",
    "    \n",
    "    print(\"Coffee shop is closed!\")\n",
    "\n",
    "coffee_shop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this code and explain how it relates to our coffee shop analogy:\n",
    "\n",
    "1. `make_coffee(order)`: This function represents a barista making a coffee. It simulates the time taken to make a coffee using `time.sleep()`.\n",
    "\n",
    "2. `coffee_shop()`: This is our main function, representing the entire coffee shop operation.\n",
    "\n",
    "3. `orders = ['Espresso', 'Latte', 'Cappuccino', 'Americano']`: These are the coffee orders we need to process.\n",
    "\n",
    "4. `with concurrent.futures.ThreadPoolExecutor(max_workers=2) as barista_team:`: This creates our team of baristas. We have 2 baristas who can work concurrently.\n",
    "\n",
    "5. `future_to_order = {barista_team.submit(make_coffee, order): order for order in orders}`: This is where we submit all our orders to the barista team. Each submission returns a Future object, which is like an order ticket.\n",
    "\n",
    "6. `for future in concurrent.futures.as_completed(future_to_order):`: This is how we check for completed orders. As each order is completed, we process it.\n",
    "\n",
    "7. `result = future.result()`: This is where we 'collect' the finished coffee. If there was a problem making the coffee, an exception would be raised here.\n",
    "\n",
    "The internal flow works like this:\n",
    "\n",
    "1. The cashier (main thread) takes all orders and submits them to the barista team (ThreadPoolExecutor).\n",
    "2. Each order becomes a Future object, which is like a ticket for that order.\n",
    "3. The baristas (worker threads) start working on the orders concurrently.\n",
    "4. The cashier can do other work while waiting for the orders to be completed.\n",
    "5. As each order is completed, the cashier checks the ticket (Future) and announces that the coffee is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Asynchronous Programming with Futures\n",
    "\n",
    "Futures can be combined with asyncio to create powerful asynchronous programs. This is particularly useful for I/O-bound tasks that involve waiting for external resources.\n",
    "\n",
    "Let's create an example that simulates fetching data from multiple APIs concurrently using asyncio and futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "async def fetch_data(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.json()\n",
    "\n",
    "async def fetch_all(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            task = asyncio.create_task(fetch_data(session, url))\n",
    "            tasks.append(task)\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "\n",
    "async def main():\n",
    "    urls = [\n",
    "        'https://api.github.com/events',\n",
    "        'https://api.github.com/emojis',\n",
    "        'https://api.github.com/meta'\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = await fetch_all(urls)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"API {i+1} returned {len(result)} items\")\n",
    "    \n",
    "    print(f\"Total time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this code and explain each part:\n",
    "\n",
    "1. `async def fetch_data(session, url):` \n",
    "   This asynchronous function fetches data from a given URL using an aiohttp session. It returns the JSON response.\n",
    "\n",
    "2. `async def fetch_all(urls):`\n",
    "   This function creates a single aiohttp session and then creates tasks for fetching data from all URLs concurrently.\n",
    "   - `async with aiohttp.ClientSession() as session:` creates a session that will be used for all requests.\n",
    "   - `task = asyncio.create_task(fetch_data(session, url))` creates a task (which is a wrapper around a coroutine) for each URL.\n",
    "   - `results = await asyncio.gather(*tasks)` waits for all tasks to complete and collects their results.\n",
    "\n",
    "3. `async def main():`\n",
    "   This is our main function that orchestrates the entire process.\n",
    "   - We define a list of URLs to fetch data from.\n",
    "   - We call `fetch_all(urls)` to fetch data from all URLs concurrently.\n",
    "   - We measure the total time taken and print the results.\n",
    "\n",
    "4. `asyncio.run(main())`\n",
    "   This runs our main coroutine, which is the entry point of our asynchronous program.\n",
    "\n",
    "This example demonstrates how futures (in the form of Tasks in asyncio) can be used to perform multiple I/O operations concurrently, potentially saving a significant amount of time compared to sequential execution.\n",
    "\n",
    "Now, let's extend this example to show how we can handle timeouts and cancellations with futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "async def fetch_data(session, url, timeout):\n",
    "    try:\n",
    "        async with session.get(url, timeout=timeout) as response:\n",
    "            return await response.json()\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Timeout occurred for {url}\")\n",
    "        return None\n",
    "\n",
    "async def fetch_all(urls, timeout):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [asyncio.create_task(fetch_data(session, url, timeout)) for url in urls]\n",
    "        return await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "async def main():\n",
    "    urls = [\n",
    "        'https://api.github.com/events',\n",
    "        'https://api.github.com/emojis',\n",
    "        'https://api.github.com/meta',\n",
    "        'https://api.github.com/non_existent'  # This URL doesn't exist\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = await fetch_all(urls, timeout=2)  # 2 second timeout\n",
    "    end_time = time.time()\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"API {i+1} encountered an error: {result}\")\n",
    "        elif result is None:\n",
    "            print(f\"API {i+1} timed out\")\n",
    "        else:\n",
    "            print(f\"API {i+1} returned {len(result)} items\")\n",
    "    \n",
    "    print(f\"Total time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this extended example:\n",
    "\n",
    "1. We've added a `timeout` parameter to `fetch_data` and `fetch_all` functions.\n",
    "\n",
    "2. In `fetch_data`, we now catch `asyncio.TimeoutError` and return `None` if a timeout occurs.\n",
    "\n",
    "3. In `fetch_all`, we use `return_exceptions=True` in `asyncio.gather()`. This means that if any task raises an exception, it will be returned in the results instead of being raised immediately.\n",
    "\n",
    "4. In `main`, we've added a non-existent URL to demonstrate error handling.\n",
    "\n",
    "5. When processing results, we now check for exceptions and timeouts:\n",
    "   - If the result is an instance of `Exception`, we print an error message.\n",
    "   - If the result is `None`, we know it timed out.\n",
    "   - Otherwise, we print the number of items returned.\n",
    "\n",
    "This example shows how futures can be used to handle concurrent operations with timeouts and error handling, which is crucial in real-world applications where network operations can fail or take too long.\n",
    "\n",
    "The use of futures (via asyncio tasks) allows us to:\n",
    "- Perform multiple I/O operations concurrently\n",
    "- Set timeouts for operations\n",
    "- Handle errors gracefully\n",
    "- Collect results as they become available\n",
    "\n",
    "These capabilities make futures a powerful tool for building efficient and robust asynchronous applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
